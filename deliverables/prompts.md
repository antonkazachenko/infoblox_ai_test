# prompts.md

No LLM calls were issued. The pipeline runs deterministically with regex/ipaddress heuristics to suit the offline environment. If enabling LLMs later, the natural seams are owner/device inference and richer hostname/FQDN consistency checks; prompts should request structured JSON with temperature â‰¤ 0.2.
